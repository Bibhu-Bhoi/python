{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemset: notebook\n",
      "Support: 0.8\n",
      "Rule:  -> notebook\n",
      "Confidence: 0.8\n",
      "Lift: 1.0\n",
      "---\n",
      "Frequent Itemset: marker, notebook\n",
      "Support: 0.4\n",
      "Rule: marker -> notebook\n",
      "Confidence: 1.0\n",
      "Lift: 1.25\n",
      "Rule: notebook -> marker\n",
      "Confidence: 0.5\n",
      "Lift: 1.25\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "# Define the list of transactions\n",
    "transactions = [\n",
    "    ['Pen', 'notebook', 'marker'],\n",
    "    ['pen', 'notebook'],\n",
    "    ['pen', 'earaser'],\n",
    "    ['notebook', 'earaser'],\n",
    "    ['notebook', 'marker']\n",
    "]\n",
    "\n",
    "# Convert min_support=2 into relative support\n",
    "min_support = 2 / len(transactions)  # because support in apyori is relative\n",
    "min_confidence = 0.5  # minimum confidence threshold\n",
    "\n",
    "# Apply the Apriori algorithm\n",
    "results = apriori(transactions, min_support=min_support, min_confidence=min_confidence)\n",
    "\n",
    "# Store the results in a list\n",
    "apriori_results = list(results)\n",
    "\n",
    "# Print the results\n",
    "for item in apriori_results:\n",
    "    # Get the frequent itemsets\n",
    "    pair = item.items\n",
    "    print(f\"Frequent Itemset: {', '.join(pair)}\")\n",
    "    \n",
    "    # Print the support\n",
    "    print(f\"Support: {item.support}\")\n",
    "    \n",
    "    # Extract and print the association rules\n",
    "    if item.ordered_statistics:\n",
    "        for stat in item.ordered_statistics:\n",
    "            print(f\"Rule: {', '.join(stat.items_base)} -> {', '.join(stat.items_add)}\")\n",
    "            print(f\"Confidence: {stat.confidence}\")\n",
    "            print(f\"Lift: {stat.lift}\")\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "    support            itemsets\n",
      "0      0.8          (notebook)\n",
      "1      0.4            (marker)\n",
      "2      0.4               (pen)\n",
      "3      0.4           (earaser)\n",
      "4      0.4  (marker, notebook)\n",
      "\n",
      "Association Rules:\n",
      "   antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0    (marker)  (notebook)                 0.4                 0.8      0.4   \n",
      "1  (notebook)    (marker)                 0.8                 0.4      0.4   \n",
      "\n",
      "   confidence  lift  leverage  conviction  zhangs_metric  \n",
      "0         1.0  1.25      0.08         inf       0.333333  \n",
      "1         0.5  1.25      0.08         1.2       1.000000  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Transaction data\n",
    "transactions = [\n",
    "    ['Pen', 'notebook', 'marker'],\n",
    "    ['pen', 'notebook'],\n",
    "    ['pen', 'earaser'],\n",
    "    ['notebook', 'earaser'],\n",
    "    ['notebook', 'marker']\n",
    "]\n",
    "\n",
    "# Step 2: Encoding the transaction data\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_data, columns=te.columns_)\n",
    "\n",
    "# Step 3: Applying FP-Growth\n",
    "# min_support: minimum support for the itemsets\n",
    "frequent_itemsets = fpgrowth(df, min_support=2/len(transactions), use_colnames=True)\n",
    "\n",
    "# Step 4: Extracting association rules\n",
    "# min_threshold: minimum confidence for the rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "#displya result\n",
    "print(\"Frequent Itemsets:\\n\", frequent_itemsets)\n",
    "print(\"\\nAssociation Rules:\\n\", rules)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
